// /api/check-new-docs.js
import { createClient } from '@supabase/supabase-js';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { Pinecone } from '@pinecone-database/pinecone';

// 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° ê²€ì¦
const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_KEY; // service_role key (í•„ìˆ˜)
const apiKey = process.env.GEMINI_API_KEY;
const pineconeKey = process.env.PINECONE_API_KEY;

if (!supabaseUrl || !supabaseKey || !apiKey || !pineconeKey) {
    console.error("âŒ [Critical] í™˜ê²½ë³€ìˆ˜ ëˆ„ë½! (SUPABASE, GEMINI, PINECONE í™•ì¸ í•„ìš”)");
}

const supabase = createClient(supabaseUrl, supabaseKey);
const genAI = new GoogleGenerativeAI(apiKey);
const pinecone = new Pinecone({ apiKey: pineconeKey });

// =========================================================
// [Helper 1] GitHub ê·œì¹™ ê°€ì ¸ì˜¤ê¸°
// =========================================================
async function fetchGithubRules() {
    const BASE_URL = 'https://raw.githubusercontent.com/Tea320771/myweb/main';
    try {
        const [readingRes, logicRes] = await Promise.all([
            fetch(`${BASE_URL}/reading_guide.json`),
            fetch(`${BASE_URL}/guideline.json`)
        ]);

        if (!readingRes.ok || !logicRes.ok) throw new Error("GitHub fetch failed");

        return {
            readingGuide: await readingRes.json(),
            logicGuideline: await logicRes.json()
        };
    } catch (error) {
        console.error("âš ï¸ GitHub ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©):", error.message);
        return { readingGuide: "Load Failed", logicGuideline: "Load Failed" };
    }
}

// =========================================================
// [Helper 2] Pinecone ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
// =========================================================
async function searchPinecone(queryText) {
    try {
        // í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (Embedding)
        const embedModel = genAI.getGenerativeModel({ model: "text-embedding-004" });
        const embedResult = await embedModel.embedContent(queryText);
        const vector = embedResult.embedding.values;

        // Pinecone ê²€ìƒ‰
        const index = pinecone.index("legal-rag-db");
        const queryResponse = await index.query({
            vector: vector,
            topK: 3,
            includeMetadata: true
        });

        if (!queryResponse.matches || queryResponse.matches.length === 0) {
            return "ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.";
        }

        // ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        return queryResponse.matches.map((match, i) => {
            const meta = match.metadata || {};
            return `[ì‚¬ë¡€ ${i + 1}] (ìœ í˜•: ${meta.docType || 'N/A'})\në‚´ìš©: ${meta.fullContent || meta.userFeedback || 'ë‚´ìš© ì—†ìŒ'}`;
        }).join("\n\n");

    } catch (error) {
        console.warn("âš ï¸ Pinecone ê²€ìƒ‰ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ì§„í–‰):", error.message);
        return "ê³¼ê±° ì‚¬ë¡€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.";
    }
}

// =========================================================
// Main Handler
// =========================================================
export default async function handler(req, res) {
    if (req.method !== 'POST' && req.method !== 'GET') {
        return res.status(405).json({ error: 'Method Not Allowed' });
    }

    try {
        console.log("ğŸš€ [RAG Pipeline] ìŠ¹ì¸ ëŒ€ê¸° ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...");

        // 1. DBì—ì„œ 'pending' ë¬¸ì„œ ì¡°íšŒ
        const { data: pendingDocs, error: dbError } = await supabase
            .from('document_queue')
            .select('*')
            .eq('status', 'pending')
            .order('created_at', { ascending: true })
            .limit(3); // RAG ì²˜ë¦¬ëŠ” ë¬´ê±°ìš°ë¯€ë¡œ í•œ ë²ˆì— 3ê°œê¹Œì§€ë§Œ ì œí•œ

        if (dbError) throw new Error(`DB ì¡°íšŒ ì‹¤íŒ¨: ${dbError.message}`);

        if (!pendingDocs || pendingDocs.length === 0) {
            console.log("âœ… ëŒ€ê¸° ì¤‘ì¸ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.");
            return res.status(200).json({ success: true, message: "No pending docs", count: 0 });
        }

        console.log(`âš¡ ${pendingDocs.length}ê°œì˜ ë¬¸ì„œë¥¼ RAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.`);
        
        // GitHub ê·œì¹™ ë¡œë“œ (í•œ ë²ˆë§Œ ë¡œë“œí•´ì„œ ì¬ì‚¬ìš©)
        const { readingGuide, logicGuideline } = await fetchGithubRules();
        const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" }); // ì†ë„/ì„±ëŠ¥ ê· í˜•

        const results = [];

        // 2. ë¬¸ì„œ ìˆœì°¨ ì²˜ë¦¬ ë£¨í”„
        for (const doc of pendingDocs) {
            console.log(`ğŸ“„ ë¶„ì„ ì‹œì‘: ${doc.filename} (ID: ${doc.id})`);

            try {
                // (A) PDF ë‹¤ìš´ë¡œë“œ
                const { data: fileBlob, error: downloadError } = await supabase.storage
                    .from('legal-docs')
                    .download(doc.filename);

                if (downloadError) {
                    console.error(`âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (Skip): ${doc.filename}`);
                    await supabase.from('document_queue').update({ status: 'error', ai_result: { error: "File not found" } }).eq('id', doc.id);
                    continue;
                }

                const arrayBuffer = await fileBlob.arrayBuffer();
                const base64 = Buffer.from(arrayBuffer).toString('base64');

                // =========================================================
                // Phase 1: Extraction & Baseline Analysis (GitHub Rules)
                // =========================================================
                console.log("   -> Phase 1: ê¸°ë³¸ ë¶„ì„ ë° ì¶”ì¶œ ìˆ˜í–‰...");
                
                const phase1Prompt = `
                ë„ˆëŠ” ë²•ë¥  ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ íŒê²°ë¬¸ì„ ì œê³µëœ ê°€ì´ë“œë¼ì¸ì— ë§ì¶° ë¶„ì„í•´.
                
                [Resource 1: Extraction Rules]
                ${JSON.stringify(readingGuide)}

                [Resource 2: Logic Guidelines]
                ${JSON.stringify(logicGuideline)}

                [Task]
                1. 'Extraction Rules'ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œì˜ ì‚¬ì‹¤ ê´€ê³„(ë‹¹ì‚¬ì, ì²­êµ¬ì·¨ì§€ ë“±)ë¥¼ ì¶”ì¶œí•´.
                2. 'Logic Guidelines'ë¥¼ ì‚¬ìš©í•˜ì—¬ 1ì°¨ì ì¸ í•´ì„(Baseline Analysis)ì„ ìˆ˜í–‰í•´.
                3. ì´ ì‚¬ê±´ì˜ í•µì‹¬ ë‚´ìš©(ê²€ìƒ‰ìš©)ì„ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´.

                ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´:
                {
                    "extraction": "ì¶”ì¶œëœ ì‚¬ì‹¤ê´€ê³„ ìš”ì•½",
                    "baseline_analysis": "ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ 1ì°¨ í•´ì„",
                    "search_context": "ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰ì„ ìœ„í•œ í•µì‹¬ ìš”ì•½ ë¬¸êµ¬"
                }
                `;

                const result1 = await model.generateContent([
                    { text: phase1Prompt },
                    { inlineData: { data: base64, mimeType: 'application/pdf' } }
                ]);

                let phase1Data;
                try {
                    let text = result1.response.text().replace(/```json/g, "").replace(/```/g, "").trim();
                    phase1Data = JSON.parse(text);
                } catch (e) {
                    console.error("Phase 1 JSON Parse Error");
                    phase1Data = { extraction: "Error", baseline_analysis: "Error", search_context: "" };
                }

                // =========================================================
                // Phase 2: Vector Search (Pinecone)
                // =========================================================
                console.log("   -> Phase 2: ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰ (Pinecone)...");
                let pastCases = "ê²€ìƒ‰ëœ ìœ ì‚¬ ì‚¬ë¡€ ì—†ìŒ";
                
                if (phase1Data.search_context) {
                    pastCases = await searchPinecone(phase1Data.search_context);
                }

                // =========================================================
                // Phase 3: Final RAG Analysis
                // =========================================================
                console.log("   -> Phase 3: ìµœì¢… RAG ë¶„ì„ (Baseline + Past Cases)...");

                const phase2Prompt = `
                ì´ì „ ë‹¨ê³„ì—ì„œ ë¶„ì„í•œ 'Baseline Analysis'ì™€ 'ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€(Past Cases)'ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë¶„ì„ì„ ìˆ˜í–‰í•´.

                [Current Analysis]
                - Extraction: ${JSON.stringify(phase1Data.extraction)}
                - Baseline: ${JSON.stringify(phase1Data.baseline_analysis)}

                [Past Similar Cases (RAG)]
                ${pastCases}

                [Task]
                ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê´€ë¦¬ìê°€ ê²€í† í•  ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´.
                ê³¼ê±° ì‚¬ë¡€ì™€ ë¹„êµí–ˆì„ ë•Œ íŠ¹ì´ì ì´ë‚˜, ê°€ì´ë“œë¼ì¸ ì ìš© ì‹œ ì£¼ì˜í•  ì ì„ í¬í•¨í•´.

                ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ìœ¼ë¡œ ì¶œë ¥í•´:
                {
                    "final_rag_analysis": "ê³¼ê±° ì‚¬ë¡€ë¥¼ ë°˜ì˜í•œ ìµœì¢… ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼",
                    "issues": ["ìŸì  1", "ìŸì  2"],
                    "rag_reference_used": true ë˜ëŠ” false (ê³¼ê±° ì‚¬ë¡€ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ì“°ì˜€ëŠ”ì§€)
                }
                `;

                const result2 = await model.generateContent([
                    { text: phase2Prompt }
                    // ì´ë¯¸ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸°ë°˜ì´ë¯€ë¡œ PDF ë‹¤ì‹œ ì•ˆ ë³´ë‚´ë„ ë¨ (í† í° ì ˆì•½)
                ]);

                let phase2Data;
                try {
                    let text = result2.response.text().replace(/```json/g, "").replace(/```/g, "").trim();
                    phase2Data = JSON.parse(text);
                } catch (e) {
                    phase2Data = { final_rag_analysis: result2.response.text(), issues: [], rag_reference_used: false };
                }

                // =========================================================
                // 3. DB ì—…ë°ì´íŠ¸ (ê´€ë¦¬ì ê²€í† ìš© ë°ì´í„° ì €ì¥)
                // =========================================================
                const finalResult = {
                    step1_extraction: phase1Data.extraction,
                    step2_baseline: phase1Data.baseline_analysis,
                    step3_rag_analysis: phase2Data.final_rag_analysis,
                    issues: phase2Data.issues,
                    past_cases_summary: pastCases.substring(0, 500) + "..." // ë„ˆë¬´ ê¸¸ë©´ ìë¦„
                };

                const { error: updateError } = await supabase
                    .from('document_queue')
                    .update({ 
                        status: 'processed', 
                        ai_result: finalResult, // ì—¬ê¸°ì— ëª¨ë“  ë‹¨ê³„ì˜ ë°ì´í„°ê°€ ì €ì¥ë¨
                        updated_at: new Date().toISOString()
                    })
                    .eq('id', doc.id);

                if (updateError) throw updateError;
                
                console.log(`âœ… ì²˜ë¦¬ ì™„ë£Œ: ${doc.filename}`);
                results.push({ filename: doc.filename, status: 'processed' });

            } catch (docError) {
                console.error(`ğŸ’¥ ê°œë³„ ì²˜ë¦¬ ì—ëŸ¬ (${doc.filename}):`, docError.message);
                await supabase.from('document_queue')
                    .update({ status: 'error', ai_result: { error: docError.message } })
                    .eq('id', doc.id);
            }
        }

        return res.status(200).json({ success: true, processed: results });

    } catch (error) {
        console.error("Global Handler Error:", error);
        return res.status(500).json({ error: error.message });
    }
}