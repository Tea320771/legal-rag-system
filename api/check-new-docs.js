// /api/check-new-docs.js
const { createClient } = require('@supabase/supabase-js');
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { Pinecone } = require('@pinecone-database/pinecone');

// [ì¶”ê°€ 1] ê°•ì œ ì§€ì—°ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
const delay = (ms) => new Promise((resolve) => setTimeout(resolve, ms));

const supabaseUrl = process.env.SUPABASE_URL;
const supabaseKey = process.env.SUPABASE_KEY;
const apiKey = process.env.GEMINI_API_KEY;
const pineconeKey = process.env.PINECONE_API_KEY;

if (!supabaseUrl || !supabaseKey || !apiKey || !pineconeKey) {
    console.error("âŒ [Critical] í™˜ê²½ë³€ìˆ˜ ëˆ„ë½!");
}

const supabase = createClient(supabaseUrl, supabaseKey);
const genAI = new GoogleGenerativeAI(apiKey);
const pinecone = new Pinecone({ apiKey: pineconeKey });

// =========================================================
// [Helper] Retry Wrapper (429 ì—ëŸ¬ ëŒ€ì‘ìš©)
// =========================================================
async function callGeminiWithRetry(fn, retries = 3, delayMs = 10000) {
    try {
        return await fn();
    } catch (error) {
        if (error.message.includes('429') && retries > 0) {
            console.warn(`âš ï¸ Quota exceeded. Retrying in ${delayMs / 1000}s... (${retries} left)`);
            await delay(delayMs);
            return callGeminiWithRetry(fn, retries - 1, delayMs * 2);
        }
        throw error;
    }
}

async function fetchGithubRules() {
    const BASE_URL = 'https://raw.githubusercontent.com/Tea320771/myweb/main';
    try {
        const [readingRes, logicRes] = await Promise.all([
            fetch(`${BASE_URL}/reading_guide.json`),
            fetch(`${BASE_URL}/guideline.json`)
        ]);
        if (!readingRes.ok || !logicRes.ok) throw new Error("GitHub fetch failed");
        return { readingGuide: await readingRes.json(), logicGuideline: await logicRes.json() };
    } catch (error) {
        console.error("âš ï¸ GitHub ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨:", error.message);
        return { readingGuide: "Load Failed", logicGuideline: "Load Failed" };
    }
}

async function searchPinecone(queryData) { 
    try {
        const queryText = typeof queryData === 'object' 
            ? JSON.stringify(queryData) 
            : String(queryData);

        const embedModel = genAI.getGenerativeModel({ model: "text-embedding-004" });
        
        const embedResult = await callGeminiWithRetry(() => embedModel.embedContent(queryText));
        const vector = embedResult.embedding.values;

        const index = pinecone.index("legal-rag-db");
        const queryResponse = await index.query({ vector, topK: 3, includeMetadata: true });

        if (!queryResponse.matches || queryResponse.matches.length === 0) return "ìœ ì‚¬í•œ ê³¼ê±° ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤.";

        return queryResponse.matches.map((match, i) => {
            const meta = match.metadata || {};
            return `[ì‚¬ë¡€ ${i + 1}] (ìœ í˜•: ${meta.docType || 'N/A'})\në‚´ìš©: ${meta.fullContent || meta.userFeedback || 'ë‚´ìš© ì—†ìŒ'}`;
        }).join("\n\n");
    } catch (error) {
        console.warn("âš ï¸ Pinecone ê²€ìƒ‰ ì‹¤íŒ¨:", error.message);
        return "ê³¼ê±° ì‚¬ë¡€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ.";
    }
}

module.exports = async function handler(req, res) {
    if (req.method !== 'POST' && req.method !== 'GET') {
        return res.status(405).json({ error: 'Method Not Allowed' });
    }

    const body = req.body || {};

    try {
        // ------------------------------------------------------------------
        // [GET] ëª©ë¡ ì¡°íšŒ (List Mode)
        // ------------------------------------------------------------------
        if (req.query.mode === 'list') {
            const { data, error } = await supabase
                .from('document_queue')
                .select('id, filename, status, created_at')
                // processed ìƒíƒœë„ ëª©ë¡ì— í¬í•¨ë˜ì–´ì•¼ ì‚¬ìš©ìê°€ í´ë¦­ ê°€ëŠ¥
                .in('status', ['pending', 'error', 'processed'])
                .order('created_at', { ascending: true });
            
            if (error) throw error;
            return res.status(200).json({ success: true, list: data });
        }

        // ------------------------------------------------------------------
        // [GET] ì¹´ìš´íŠ¸ ì¡°íšŒ (Count Mode)
        // ------------------------------------------------------------------
        if (req.query.mode === 'count') {
            const { count, error } = await supabase
                .from('document_queue')
                .select('*', { count: 'exact', head: true })
                .in('status', ['pending', 'error', 'processed']); 

            if (error) throw error;
            return res.status(200).json({ success: true, count: count || 0 });
        }

        // ------------------------------------------------------------------
        // [POST] ë¬¸ì„œ ë¶„ì„ ë° ìƒì„¸ ì¡°íšŒ (Pipeline)
        // ------------------------------------------------------------------
        console.log("ğŸš€ [RAG Pipeline] ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...");

        let query = supabase.from('document_queue').select('*');

        // [í•µì‹¬ ë³€ê²½ 1] íŠ¹ì • ID ìš”ì²­ ì‹œ, ìƒíƒœ ì œí•œ ì—†ì´ ê°€ì ¸ì˜¤ê¸°
        if (body.docId) {
            console.log(`ğŸ¯ ê°œë³„ ì²˜ë¦¬ ìš”ì²­: ID ${body.docId}`);
            query = query.eq('id', body.docId); // status í•„í„° ì œê±° (processedë„ ê°€ì ¸ì˜´)
        } else {
            // [ìë™ ì‹¤í–‰] ìë™ ì‹¤í–‰ì¼ ë•ŒëŠ” ì—¬ì „íˆ ëŒ€ê¸° ì¤‘ì¸ ê²ƒë§Œ ì²˜ë¦¬
            query = query.in('status', ['pending', 'error'])
                         .order('created_at', { ascending: true })
                         .limit(1);
        }

        const { data: pendingDocs, error: dbError } = await query;

        if (dbError) throw new Error(`DB ì¡°íšŒ ì‹¤íŒ¨: ${dbError.message}`);

        if (!pendingDocs || pendingDocs.length === 0) {
            console.log("âœ… ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.");
            return res.status(200).json({ success: true, count: 0, processed: [] });
        }

        const { readingGuide, logicGuideline } = await fetchGithubRules();
        const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
        const results = [];

        for (const doc of pendingDocs) {
            
            // [í•µì‹¬ ë³€ê²½ 2] ì´ë¯¸ ë¶„ì„ ì™„ë£Œëœ ë¬¸ì„œëŠ” ì¬ë¶„ì„ ì—†ì´ DB ê²°ê³¼ ë°˜í™˜
            if (doc.status === 'processed' && doc.ai_result) {
                console.log(`â„¹ï¸ [Cache] ì´ë¯¸ ë¶„ì„ëœ ë¬¸ì„œì…ë‹ˆë‹¤: ${doc.filename}`);
                // ì´ë¯¸ ì €ì¥ëœ ai_resultë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
                results.push({ 
                    filename: doc.filename, 
                    status: 'processed', 
                    result: doc.ai_result 
                });
                continue; // ë‹¤ìŒ ë£¨í”„ë¡œ ê±´ë„ˆëœ€ (API í˜¸ì¶œ ìƒëµ)
            }

            // ---------------------------------------------------------
            // ì•„ë˜ë¶€í„°ëŠ” 'pending' ë˜ëŠ” 'error' ìƒíƒœì¸ ë¬¸ì„œì˜ ì‹¤ì œ ë¶„ì„ ë¡œì§
            // ---------------------------------------------------------
            console.log(`ğŸ“„ ì‹ ê·œ ë¶„ì„ ì‹œì‘: ${doc.filename} (ID: ${doc.id})`);

            try {
                const { data: fileBlob, error: downloadError } = await supabase.storage
                    .from('legal-docs')
                    .download(doc.filename);

                if (downloadError) {
                    console.error(`âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: ${doc.filename}`);
                    continue; 
                }

                const arrayBuffer = await fileBlob.arrayBuffer();
                const base64 = Buffer.from(arrayBuffer).toString('base64');

                // Phase 1: Gemini Call
                const phase1Prompt = `
                ë„ˆëŠ” ë²•ë¥  ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼. 
                [Extraction Rules]: ${JSON.stringify(readingGuide)}
                [Logic Guidelines]: ${JSON.stringify(logicGuideline)}
                
                ìœ„ ê·œì¹™ì„ ì‚¬ìš©í•˜ì—¬:
                1. ì‚¬ì‹¤ ê´€ê³„ ì¶”ì¶œ (Extraction)
                2. 1ì°¨ í•´ì„ (Baseline Analysis)
                3. ê²€ìƒ‰ìš© ìš”ì•½ (Search Context)
                
                JSON í¬ë§·: { "extraction": "...", "baseline_analysis": "...", "search_context": "..." }
                `;

                const result1 = await callGeminiWithRetry(() => model.generateContent([
                    { text: phase1Prompt },
                    { inlineData: { data: base64, mimeType: 'application/pdf' } }
                ]));
                
                await delay(5000); 

                let phase1Data;
                try {
                    phase1Data = JSON.parse(result1.response.text().replace(/```json/g, "").replace(/```/g, "").trim());
                } catch(e) {
                    phase1Data = { extraction: "Error", baseline_analysis: "Error", search_context: "" };
                }

                // Phase 2: Vector Search
                let pastCases = "ê²€ìƒ‰ëœ ìœ ì‚¬ ì‚¬ë¡€ ì—†ìŒ";
                if (phase1Data.search_context) {
                    pastCases = await searchPinecone(phase1Data.search_context);
                    await delay(2000);
                }

                // Phase 3: Final Analysis
                const phase2Prompt = `
                [Baseline]: ${JSON.stringify(phase1Data.baseline_analysis)}
                [Past Cases]: ${pastCases}
                
                ìœ„ ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ê´€ë¦¬ììš© ìµœì¢… ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´.
                JSON í¬ë§·: { "final_rag_analysis": "...", "issues": ["..."], "rag_reference_used": boolean }
                `;

                const result2 = await callGeminiWithRetry(() => model.generateContent([{ text: phase2Prompt }]));
                
                let phase2Data;
                try {
                    phase2Data = JSON.parse(result2.response.text().replace(/```json/g, "").replace(/```/g, "").trim());
                } catch(e) {
                    phase2Data = { final_rag_analysis: result2.response.text(), issues: [], rag_reference_used: false };
                }

                const finalResult = {
                    step1_extraction: phase1Data.extraction,
                    step2_baseline: phase1Data.baseline_analysis,
                    step3_rag_analysis: phase2Data.final_rag_analysis,
                    issues: phase2Data.issues,
                    past_cases_summary: pastCases.substring(0, 500)
                };

                const { error: updateError } = await supabase
                    .from('document_queue')
                    .update({ 
                        status: 'processed', 
                        ai_result: finalResult,
                    })
                    .eq('id', doc.id);

                if (updateError) throw updateError;
                console.log(`âœ… ì²˜ë¦¬ ì™„ë£Œ: ${doc.filename}`);
                results.push({ filename: doc.filename, status: 'processed', result: finalResult });

                await delay(10000); 

            } catch (docError) {
                console.error(`ğŸ’¥ ì—ëŸ¬ ë°œìƒ (${doc.filename}):`, docError.message);
                
                await supabase.from('document_queue')
                    .update({ status: 'error', ai_result: { error: docError.message } })
                    .eq('id', doc.id);
                    
                results.push({ filename: doc.filename, status: 'error', error: docError.message });
            }
        }

        return res.status(200).json({ success: true, processed: results });

    } catch (error) {
        console.error("Handler Error:", error);
        return res.status(500).json({ error: error.message });
    }
}